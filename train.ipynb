{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freshpate/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.9.0-dev20211227). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from data_manager import DataManager, load_img, list_images\n",
    "from data_generator import CustomDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "import tensorflow\n",
    "from model import UNet\n",
    "import tensorflow.keras.activations as activations\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import skimage\n",
    "import scipy.spatial.distance as spdist\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  ['/physical_device:GPU:0']\n",
      "Running on GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "print(\"Available GPUs: \", [gpu.name for gpu in gpus])\n",
    "gpu_index = 0\n",
    "print(f\"Running on GPU {gpu_index}\")\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[gpu_index], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[gpu_index], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.getcwd()\n",
    "manager = DataManager()\n",
    "BATCH_SIZE = 6\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_not_blank(mask):\n",
    "    return sum(mask.flatten()) > 0\n",
    "\n",
    "def plot_image(img, title=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def resize2SquareKeepingAspectRation(img, size, interpolation):\n",
    "    h, w = img.shape[:2]\n",
    "    c = None if len(img.shape) < 3 else img.shape[2]\n",
    "    if h == w: \n",
    "        return cv2.resize(img, (size, size), interpolation)\n",
    "    if h > w: \n",
    "        dif = h\n",
    "    else:     \n",
    "        dif = w\n",
    "    x_pos = int((dif - w)/2.)\n",
    "    y_pos = int((dif - h)/2.)\n",
    "    if c is None:\n",
    "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "    return cv2.resize(mask, (size, size), interpolation)\n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn image into grayscale RGB\n",
    "    return np.array(Image.fromarray(img).convert(\"RGB\"))\n",
    "\n",
    "def save_img(img, img_idx, path, pid, is_mask=False):\n",
    "    filename = path + '/' + str(pid) + '_' + str(img_idx) \n",
    "    if is_mask: \n",
    "        filename += '_mask.png' \n",
    "        img = np.asarray(img, dtype=\"uint8\") # convert bool mask into uint8 so cv2 doesn't scream\n",
    "    else:\n",
    "        filename += '.png'\n",
    "        img = grays_to_RGB(img)\n",
    "    \n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (f\"Creation of the directory {path} failed\", end='\\r')\n",
    "\n",
    "def gen_dataset(imgs, dataset, pid, labels=None, typeof_dataset=None):\n",
    "    output_dir = BASE + '/data/'+dataset+'/'\n",
    "    if os.path.isdir(output_dir) is False:\n",
    "        make_dir(output_dir)\n",
    "    if typeof_dataset is not None: # this is only for train\n",
    "        output_dir+=typeof_dataset #+ '/'\n",
    "        if os.path.isdir(output_dir) is False:\n",
    "            make_dir(output_dir)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        save_img(img, i, output_dir, pid)\n",
    "        if labels is not None: # this is only for train\n",
    "            save_img(labels[i], i, output_dir, pid, is_mask=True)\n",
    "    \n",
    "def list_images(directory, ext='jpg|jpeg|bmp|png|tif'):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if os.path.isfile(os.path.join(directory, f)) and re.match('([\\w]+\\.(?:' + ext + '))', f)]\n",
    "\n",
    "def preprocess(img, denoise=False):\n",
    "    \"\"\"\n",
    "    Preprocess step after image augmentation, and before feeding into conv net.\n",
    "    \"\"\"\n",
    "    if denoise:\n",
    "        img = cv2.fastNlMeansDenoising(img, h=7)\n",
    "    \n",
    "    img = resize2SquareKeepingAspectRation(img, DataManager.EX_IMG_TARGET_COLS, cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform(img, mask, augment=True):\n",
    "    \"\"\"\n",
    "    Transforms an (img, mask) pair with same augmentation params\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        pass\n",
    "        #img, mask = augmenter.augment_batch(np.array([img, mask]), same_transform=True)\n",
    "    img = preprocess(img)\n",
    "    mask = preprocess(mask).astype('float32')\n",
    "    return np.array([img]), np.array([mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prind_de_pula(images, labels):\n",
    "    sim=dict()\n",
    "    for i in tqdm(range(len(images))):\n",
    "        for j in range(len(images)):\n",
    "            if i!=j:\n",
    "                if tuple(sorted((i,j))) not in sim.keys():\n",
    "                    simil=ssim(images[i], images[j])\n",
    "                    if abs(simil)>0.90:\n",
    "                        sim[tuple(sorted((i,j)))]=simil\n",
    "    print(sim)\n",
    "    return 0\n",
    "    conf=[]\n",
    "    for i in tqdm(sim.keys()):\n",
    "        if sim[i]>0.99:\n",
    "            msk1=cv2.imread(img.mask_path.iloc[i[0]],cv2.IMREAD_GRAYSCALE)\n",
    "            msk2=cv2.imread(img.mask_path.iloc[i[1]],cv2.IMREAD_GRAYSCALE)\n",
    "            if msk1.any()!=msk2.any():\n",
    "                conf.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = load_zipped_pickle(\"data/train.pkl\")\n",
    "# test_data = load_zipped_pickle(\"data/test.pkl\")\n",
    "# for data in tqdm(train_data, total=len(train_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     typeof_ds = data['dataset']\n",
    "#     labels = data['label'].T\n",
    "#     pacient = data['name']\n",
    "#     prind_de_pula(imgs, labels)\n",
    "#     print(data['frames'])\n",
    "#     break\n",
    "#     gen_dataset(imgs, \"train\", pacient, labels, typeof_ds)\n",
    "\n",
    "# for data in tqdm(test_data, total=len(test_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     pacient = data['name']\n",
    "#     gen_dataset(imgs, \"test\", pacient)\n",
    "# min_w = 1000\n",
    "# max_w = 0\n",
    "# min_h = 1000\n",
    "# max_h = 0\n",
    "# for data in tqdm(test_data, total=len(test_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     pacient = data['name']\n",
    "#     if min_w > imgs.shape[1]:\n",
    "#         min_w = imgs.shape[1]\n",
    "#     if max_w < imgs.shape[1]:\n",
    "#         max_w = imgs.shape[1]\n",
    "#     if min_h > imgs.shape[2]:\n",
    "#         min_h = imgs.shape[2]\n",
    "#     if max_h < imgs.shape[2]:\n",
    "#         max_h = imgs.shape[2]\n",
    "\n",
    "# print(\"Min width: {} Max width: {}\".format(min_w, max_w))\n",
    "# print(\"Min height: {} Max height: {}\".format(min_h, max_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = manager.load_train_val_data(\"expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_train, X_val], axis=0)\n",
    "y = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = CustomDataGenerator(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    (224, 224),\n",
    "    preprocess,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=5, #degrees\n",
    "    width_shift_range=10, #pixels, if <1 fraction\n",
    "    height_shift_range=10,\n",
    "    horizontal_flip=False,\n",
    "    shear_range=5,\n",
    "    rescale=1./255)\n",
    "    #preprocessing_function=preprocess)\n",
    "datagen.generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_mask(img, mask, title=None):\n",
    "    \"\"\"\n",
    "    this does the same thing as plot_separate but plots only the overlayed img\n",
    "    \"\"\"\n",
    "    # returns a copy of the image with edges of the mask added in red\n",
    "    img_mask = np.ma.masked_where(mask == False, mask)\n",
    "    #img_box = np.ma.masked_where(box == False, box)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(img, cmap = 'gray', interpolation = 'none')\n",
    "    plt.imshow(img_mask, cmap = 'jet', interpolation = 'none', alpha = 0.8)\n",
    "    #plt.imshow(img_box, cmap = 'spring', interpolation = 'none', alpha = 0.5)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for _ in range(len(X_train) // 2):\n",
    "    batch_x, batch_y = datagen.next()\n",
    "    yy = batch_y['output_2']\n",
    "    if np.sum(yy) > 0:\n",
    "        plot_image_with_mask(batch_x[0], batch_y['output_1'][0])\n",
    "        #plot_image(batch_y['output_1'][0])\n",
    "        #print(batch_y['output_1'][0].dtype)\n",
    "        #print(batch_x[0].dtype)\n",
    "        plt.show()\n",
    "        i += 1\n",
    "    if i == 10:\n",
    "        break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_val = CustomDataGenerator(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    (224, 224),\n",
    "    preprocess,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=5, #degrees\n",
    "    width_shift_range=10, #pixels, if <1 fraction\n",
    "    height_shift_range=10,\n",
    "    horizontal_flip=False,\n",
    "    shear_range=5,\n",
    "    rescale=1./255)\n",
    "    #preprocessing_function=preprocess)\n",
    "datagen_val.generator.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datagen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 20:11:48.617933: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-30 20:11:49.389240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5215 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 224, 224, 32)      9760      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 112, 112, 64)      55808     \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 56, 56, 128)       222208    \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 28, 28, 256)       886784    \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 14, 14, 512)       3543040   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          multiple                  100353    \n",
      "                                                                 \n",
      " aux_output (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 28, 28, 256)       1771520   \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 56, 56, 128)       443392    \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 112, 112, 64)      111104    \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 224, 224, 32)      27904     \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          multiple                  289       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 28, 28, 256)       2097152   \n",
      "                                                                 \n",
      " sequential_10 (Sequential)  (None, 56, 56, 128)       524288    \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 112, 112, 64)      131072    \n",
      "                                                                 \n",
      " sequential_12 (Sequential)  (None, 224, 224, 32)      32768     \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,957,442\n",
      "Trainable params: 9,951,554\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Training on model\n"
     ]
    }
   ],
   "source": [
    "net = UNet(True)\n",
    "net.build((None, 224, 224, 1))\n",
    "net.summary()\n",
    "run_id = str(datetime.now())\n",
    "model_checkpoint = ModelCheckpoint('./results/net', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "tb = TensorBoard(log_dir='./logs/{}'.format(run_id), histogram_freq=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=4, min_lr=1e-6)\n",
    "print('Training on model')\n",
    "net.compile(optimizer='adam',\n",
    "                  loss={'output_1': 'binary_crossentropy', 'output_2': 'binary_crossentropy'},\n",
    "                  metrics={'output_1': tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), 'output_2': 'acc'},\n",
    "                  loss_weights={'output_1': 1, 'output_2': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 20:12:10.662768: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/163 [=====>........................] - ETA: 3:49 - loss: 0.4708 - output_1_loss: 0.1857 - output_2_loss: 0.5703 - output_1_io_u: 0.9999 - output_2_acc: 0.9643"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55177/3794324955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagen_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 _r=1):\n\u001b[1;32m   1384\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.fit(datagen, validation_data=datagen_val, epochs=2, steps_per_epoch=len(X_train)//8, validation_steps=X_val.shape[0]//8, callbacks=[model_checkpoint, reduce_lr, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, validation_data=val_generator, validation_steps=X_val.shape[0],\n",
    "                     steps_per_epoch=X_train.shape[0], epochs=EPOCHS, verbose=2,\n",
    "                     callbacks=[model_checkpoint, reduce_lr, tb], max_queue_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
