{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from data_manager import DataManager, load_img\n",
    "from data_generator import CustomDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    concatenate,\n",
    "    Convolution2D,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    ELU,\n",
    "    Dense\n",
    ")\n",
    "import tensorflow\n",
    "import tensorflow.keras.activations as activations\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.getcwd()\n",
    "manager = DataManager()\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def resize_with_padding(img, expected_size):\n",
    "    \"\"\"\n",
    "    this function only works when scaling UP i.e. left,right,top,bottom > 0\n",
    "    \"\"\"\n",
    "    desired_size = expected_size\n",
    "    height, width = img.shape[:2]\n",
    "    delta_width = desired_size[1] - width\n",
    "    delta_height = desired_size[0] - height\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "    left, top, right, bottom = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    img = cv2.resize(img, expected_size)\n",
    "    color = [0,0,0]\n",
    "    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "        value=color)\n",
    "    return new_img\n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn image into grayscale RGB\n",
    "    return np.array(Image.fromarray(img).convert(\"RGB\"))\n",
    "\n",
    "def save_img(img, img_idx, path, pid, is_mask=False):\n",
    "    filename = path + '/' + str(pid) + '_' + str(img_idx) \n",
    "    if is_mask: \n",
    "        filename += '_mask.png' \n",
    "        img = np.asarray(img, dtype=\"uint8\") # convert bool mask into uint8 so cv2 doesn't scream\n",
    "    else:\n",
    "        filename += '.png'\n",
    "        img = grays_to_RGB(img)\n",
    "    \n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (f\"Creation of the directory {path} failed\", end='\\r')\n",
    "\n",
    "def gen_dataset(imgs, dataset, pid, labels=None, typeof_dataset=None):\n",
    "    output_dir = BASE + '/data/'+dataset+'/'\n",
    "    if os.path.isdir(output_dir) is False:\n",
    "        make_dir(output_dir)\n",
    "    if typeof_dataset is not None: # this is only for train\n",
    "        output_dir+=typeof_dataset + '/'\n",
    "        if os.path.isdir(output_dir) is False:\n",
    "            make_dir(output_dir)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        save_img(img, i, output_dir, pid)\n",
    "        if labels is not None: # this is only for train\n",
    "            save_img(labels[i], i, output_dir, pid, is_mask=True)\n",
    "    \n",
    "def list_images(directory, ext='jpg|jpeg|bmp|png|tif'):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if os.path.isfile(os.path.join(directory, f)) and re.match('([\\w]+\\.(?:' + ext + '))', f)]\n",
    "\n",
    "def preprocess(img, denoise=False):\n",
    "    \"\"\"\n",
    "    Preprocess step after image augmentation, and before feeding into conv net.\n",
    "    \"\"\"\n",
    "    if denoise:\n",
    "        img = cv2.fastNlMeansDenoising(img, h=7)\n",
    "    img = cv2.resize(img, (DataManager.EX_IMG_TARGET_COLS, DataManager.EX_IMG_TARGET_COLS))\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform(img, mask, augment=True):\n",
    "    \"\"\"\n",
    "    Transforms an (img, mask) pair with same augmentation params\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        pass\n",
    "        #img, mask = augmenter.augment_batch(np.array([img, mask]), same_transform=True)\n",
    "    img = preprocess(img)\n",
    "    mask = preprocess(mask).astype('float32')\n",
    "    return np.array([img]), np.array([mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_zipped_pickle(\"data/train.pkl\")\n",
    "test_data = load_zipped_pickle(\"data/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:08<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(train_data, total=len(train_data)):\n",
    "    imgs = data['video'].T\n",
    "    typeof_ds = data['dataset']\n",
    "    labels = data['label'].T\n",
    "    pacient = data['name']\n",
    "    gen_dataset(imgs, \"train\", pacient, labels, typeof_ds)\n",
    "\n",
    "for data in tqdm(test_data, total=len(test_data)):\n",
    "    imgs = data['video'].T\n",
    "    pacient = data['name']\n",
    "    gen_dataset(imgs, \"test\", pacient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_images(BASE+'/data/train/expert'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16340"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_images(BASE+'/data/train/amateur'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 180788.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min width: 600 Max width: 1007\n",
      "Min height: 582 Max height: 732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_w = 1000\n",
    "max_w = 0\n",
    "min_h = 1000\n",
    "max_h = 0\n",
    "for data in tqdm(test_data, total=len(test_data)):\n",
    "    imgs = data['video'].T\n",
    "    pacient = data['name']\n",
    "    if min_w > imgs.shape[1]:\n",
    "        min_w = imgs.shape[1]\n",
    "    if max_w < imgs.shape[1]:\n",
    "        max_w = imgs.shape[1]\n",
    "    if min_h > imgs.shape[2]:\n",
    "        min_h = imgs.shape[2]\n",
    "    if max_h < imgs.shape[2]:\n",
    "        max_h = imgs.shape[2]\n",
    "\n",
    "print(\"Min width: {} Max width: {}\".format(min_w, max_w))\n",
    "print(\"Min height: {} Max height: {}\".format(min_h, max_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems scaling down for now should be the way to go:\n",
    "https://datascience.stackexchange.com/questions/30396/why-do-we-scale-down-images-before-feeding-them-to-the-network\n",
    "Let's try 224 x 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training amateur images...\n",
      "Done: 0/8170 images\n",
      "Done: 100/8170 images\n",
      "Done: 200/8170 images\n",
      "Done: 300/8170 images\n",
      "Done: 400/8170 images\n",
      "Done: 500/8170 images\n",
      "Done: 600/8170 images\n",
      "Done: 700/8170 images\n",
      "Done: 800/8170 images\n",
      "Done: 900/8170 images\n",
      "Done: 1000/8170 images\n",
      "Done: 1100/8170 images\n",
      "Done: 1200/8170 images\n",
      "Done: 1300/8170 images\n",
      "Done: 1400/8170 images\n",
      "Done: 1500/8170 images\n",
      "Done: 1600/8170 images\n",
      "Done: 1700/8170 images\n",
      "Done: 1800/8170 images\n",
      "Done: 1900/8170 images\n",
      "Done: 2000/8170 images\n",
      "Done: 2100/8170 images\n",
      "Done: 2200/8170 images\n",
      "Done: 2300/8170 images\n",
      "Done: 2400/8170 images\n",
      "Done: 2500/8170 images\n",
      "Done: 2600/8170 images\n",
      "Done: 2700/8170 images\n",
      "Done: 2800/8170 images\n",
      "Done: 2900/8170 images\n",
      "Done: 3000/8170 images\n",
      "Done: 3100/8170 images\n",
      "Done: 3200/8170 images\n",
      "Done: 3300/8170 images\n",
      "Done: 3400/8170 images\n",
      "Done: 3500/8170 images\n",
      "Done: 3600/8170 images\n",
      "Done: 3700/8170 images\n",
      "Done: 3800/8170 images\n",
      "Done: 3900/8170 images\n",
      "Done: 4000/8170 images\n",
      "Done: 4100/8170 images\n",
      "Done: 4200/8170 images\n",
      "Done: 4300/8170 images\n",
      "Done: 4400/8170 images\n",
      "Done: 4500/8170 images\n",
      "Done: 4600/8170 images\n",
      "Done: 4700/8170 images\n",
      "Done: 4800/8170 images\n",
      "Done: 4900/8170 images\n",
      "Done: 5000/8170 images\n",
      "Done: 5100/8170 images\n",
      "Done: 5200/8170 images\n",
      "Done: 5300/8170 images\n",
      "Done: 5400/8170 images\n",
      "Done: 5500/8170 images\n",
      "Done: 5600/8170 images\n",
      "Done: 5700/8170 images\n",
      "Done: 5800/8170 images\n",
      "Done: 5900/8170 images\n",
      "Done: 6000/8170 images\n",
      "Done: 6100/8170 images\n",
      "Done: 6200/8170 images\n",
      "Done: 6300/8170 images\n",
      "Done: 6400/8170 images\n",
      "Done: 6500/8170 images\n",
      "Done: 6600/8170 images\n",
      "Done: 6700/8170 images\n",
      "Done: 6800/8170 images\n",
      "Done: 6900/8170 images\n",
      "Done: 7000/8170 images\n",
      "Done: 7100/8170 images\n",
      "Done: 7200/8170 images\n",
      "Done: 7300/8170 images\n",
      "Done: 7400/8170 images\n",
      "Done: 7500/8170 images\n",
      "Done: 7600/8170 images\n",
      "Done: 7700/8170 images\n",
      "Done: 7800/8170 images\n",
      "Done: 7900/8170 images\n",
      "Done: 8000/8170 images\n",
      "Done: 8100/8170 images\n",
      "Loading training expert images...\n",
      "Done: 0/1634 images\n",
      "Done: 100/1634 images\n",
      "Done: 200/1634 images\n",
      "Done: 300/1634 images\n",
      "Done: 400/1634 images\n",
      "Done: 500/1634 images\n",
      "Done: 600/1634 images\n",
      "Done: 700/1634 images\n",
      "Done: 800/1634 images\n",
      "Done: 900/1634 images\n",
      "Done: 1000/1634 images\n",
      "Done: 1100/1634 images\n",
      "Done: 1200/1634 images\n",
      "Done: 1300/1634 images\n",
      "Done: 1400/1634 images\n",
      "Done: 1500/1634 images\n",
      "Done: 1600/1634 images\n"
     ]
    }
   ],
   "source": [
    "amateur, expert = manager.read_train_images() # just for demonstration purposes, this gets called internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8170, 112, 112)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amateur[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1634, 224, 224)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training amateur images...\n",
      "Done: 0/8170 images\n",
      "Done: 100/8170 images\n",
      "Done: 200/8170 images\n",
      "Done: 300/8170 images\n",
      "Done: 400/8170 images\n",
      "Done: 500/8170 images\n",
      "Done: 600/8170 images\n",
      "Done: 700/8170 images\n",
      "Done: 800/8170 images\n",
      "Done: 900/8170 images\n",
      "Done: 1000/8170 images\n",
      "Done: 1100/8170 images\n",
      "Done: 1200/8170 images\n",
      "Done: 1300/8170 images\n",
      "Done: 1400/8170 images\n",
      "Done: 1500/8170 images\n",
      "Done: 1600/8170 images\n",
      "Done: 1700/8170 images\n",
      "Done: 1800/8170 images\n",
      "Done: 1900/8170 images\n",
      "Done: 2000/8170 images\n",
      "Done: 2100/8170 images\n",
      "Done: 2200/8170 images\n",
      "Done: 2300/8170 images\n",
      "Done: 2400/8170 images\n",
      "Done: 2500/8170 images\n",
      "Done: 2600/8170 images\n",
      "Done: 2700/8170 images\n",
      "Done: 2800/8170 images\n",
      "Done: 2900/8170 images\n",
      "Done: 3000/8170 images\n",
      "Done: 3100/8170 images\n",
      "Done: 3200/8170 images\n",
      "Done: 3300/8170 images\n",
      "Done: 3400/8170 images\n",
      "Done: 3500/8170 images\n",
      "Done: 3600/8170 images\n",
      "Done: 3700/8170 images\n",
      "Done: 3800/8170 images\n",
      "Done: 3900/8170 images\n",
      "Done: 4000/8170 images\n",
      "Done: 4100/8170 images\n",
      "Done: 4200/8170 images\n",
      "Done: 4300/8170 images\n",
      "Done: 4400/8170 images\n",
      "Done: 4500/8170 images\n",
      "Done: 4600/8170 images\n",
      "Done: 4700/8170 images\n",
      "Done: 4800/8170 images\n",
      "Done: 4900/8170 images\n",
      "Done: 5000/8170 images\n",
      "Done: 5100/8170 images\n",
      "Done: 5200/8170 images\n",
      "Done: 5300/8170 images\n",
      "Done: 5400/8170 images\n",
      "Done: 5500/8170 images\n",
      "Done: 5600/8170 images\n",
      "Done: 5700/8170 images\n",
      "Done: 5800/8170 images\n",
      "Done: 5900/8170 images\n",
      "Done: 6000/8170 images\n",
      "Done: 6100/8170 images\n",
      "Done: 6200/8170 images\n",
      "Done: 6300/8170 images\n",
      "Done: 6400/8170 images\n",
      "Done: 6500/8170 images\n",
      "Done: 6600/8170 images\n",
      "Done: 6700/8170 images\n",
      "Done: 6800/8170 images\n",
      "Done: 6900/8170 images\n",
      "Done: 7000/8170 images\n",
      "Done: 7100/8170 images\n",
      "Done: 7200/8170 images\n",
      "Done: 7300/8170 images\n",
      "Done: 7400/8170 images\n",
      "Done: 7500/8170 images\n",
      "Done: 7600/8170 images\n",
      "Done: 7700/8170 images\n",
      "Done: 7800/8170 images\n",
      "Done: 7900/8170 images\n",
      "Done: 8000/8170 images\n",
      "Done: 8100/8170 images\n",
      "Loading training expert images...\n",
      "Done: 0/1634 images\n",
      "Done: 100/1634 images\n",
      "Done: 200/1634 images\n",
      "Done: 300/1634 images\n",
      "Done: 400/1634 images\n",
      "Done: 500/1634 images\n",
      "Done: 600/1634 images\n",
      "Done: 700/1634 images\n",
      "Done: 800/1634 images\n",
      "Done: 900/1634 images\n",
      "Done: 1000/1634 images\n",
      "Done: 1100/1634 images\n",
      "Done: 1200/1634 images\n",
      "Done: 1300/1634 images\n",
      "Done: 1400/1634 images\n",
      "Done: 1500/1634 images\n",
      "Done: 1600/1634 images\n",
      "Creating train dataset...\n",
      "Saving amateur .npy files done.\n",
      "Saving expert .npy files done.\n"
     ]
    }
   ],
   "source": [
    "manager.create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test images...\n",
      "Done: 0/1572 images\n",
      "Done: 100/1572 images\n",
      "Done: 200/1572 images\n",
      "Done: 300/1572 images\n",
      "Done: 400/1572 images\n",
      "Done: 500/1572 images\n",
      "Done: 600/1572 images\n",
      "Done: 700/1572 images\n",
      "Done: 800/1572 images\n",
      "Done: 900/1572 images\n",
      "Done: 1000/1572 images\n",
      "Done: 1100/1572 images\n",
      "Done: 1200/1572 images\n",
      "Done: 1300/1572 images\n",
      "Done: 1400/1572 images\n",
      "Done: 1500/1572 images\n",
      "Saving test samples...\n",
      "Saving to .npy files done.\n"
     ]
    }
   ],
   "source": [
    "manager.create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = manager.load_train_val_data(\"expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 224, 224)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 224, 224)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Average dice across all samples\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)\n",
    "\n",
    "# Helper to build a conv -> BN -> relu block\n",
    "def _conv_bn_relu(filters, k_row, k_col, strides=(1, 1)):\n",
    "    def f(input):\n",
    "        conv = Convolution2D(filters=filters, kernel_size=[k_row, k_col],\n",
    "                             strides=strides, kernel_initializer=\"he_normal\",\n",
    "                             padding=\"same\")(input)\n",
    "        norm = BatchNormalization()(conv)\n",
    "        return ELU()(norm)\n",
    "    return f\n",
    "\n",
    "\n",
    "def build_model(optimizer=None):\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "    inputs = Input((1, DataManager.EX_IMG_TARGET_ROWS, DataManager.EX_IMG_TARGET_COLS), name='main_input')\n",
    "    conv1 = _conv_bn_relu(32, 7, 7)(inputs)\n",
    "    conv1 = _conv_bn_relu(32, 3, 3)(conv1)\n",
    "    pool1 = _conv_bn_relu(32, 2, 2, strides=(2, 2))(conv1)\n",
    "    drop1 = Dropout(0.5)(pool1)\n",
    "\n",
    "    conv2 = _conv_bn_relu(64, 3, 3)(drop1)\n",
    "    conv2 = _conv_bn_relu(64, 3, 3)(conv2)\n",
    "    pool2 = _conv_bn_relu(64, 2, 2, strides=(2, 2))(conv2)\n",
    "    drop2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = _conv_bn_relu(128, 3, 3)(drop2)\n",
    "    conv3 = _conv_bn_relu(128, 3, 3)(conv3)\n",
    "    pool3 = _conv_bn_relu(128, 2, 2, strides=(2, 2))(conv3)\n",
    "    drop3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = _conv_bn_relu(256, 3, 3)(drop3)\n",
    "    conv4 = _conv_bn_relu(256, 3, 3)(conv4)\n",
    "    pool4 = _conv_bn_relu(256, 2, 2, strides=(2, 2))(conv4)\n",
    "    drop4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    conv5 = _conv_bn_relu(512, 3, 3)(drop4)\n",
    "    conv5 = _conv_bn_relu(512, 3, 3)(conv5)\n",
    "\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    # Using conv to mimic fully connected layer.\n",
    "    aux = Dense(512, kernel_initializer=\"he_normal\", activation='sigmoid')(drop5)\n",
    "    #Convolution2D(filters=1, kernel_size=[drop5.shape[1], drop5.shape[2]],\n",
    "    #                    strides=(1, 1), kernel_initializer=\"he_normal\", activation='sigmoid')(drop5)\n",
    "    \n",
    "    aux = Flatten(name='aux_output')(aux)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(1,2))(drop5), conv4], axis=-1)\n",
    "    conv6 = _conv_bn_relu(256, 3, 3)(up6)\n",
    "    conv6 = _conv_bn_relu(256, 3, 3)(conv6)\n",
    "    drop6 = Dropout(0.5)(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(1,2))(drop6), conv3], axis=3)\n",
    "    conv7 = _conv_bn_relu(128, 3, 3)(up7)\n",
    "    conv7 = _conv_bn_relu(128, 3, 3)(conv7)\n",
    "    drop7 = Dropout(0.5)(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(1,2))(drop7), conv2], axis=3)\n",
    "    conv8 = _conv_bn_relu(64, 3, 3)(up8)\n",
    "    conv8 = _conv_bn_relu(64, 3, 3)(conv8)\n",
    "    drop8 = Dropout(0.5)(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(1,2))(drop8), conv1],axis=3)\n",
    "    conv9 = _conv_bn_relu(32, 3, 3)(up9)\n",
    "    conv9 = _conv_bn_relu(32, 3, 3)(conv9)\n",
    "    drop9 = Dropout(0.5)(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid', kernel_initializer=\"he_normal\", name='main_output')(drop9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[conv10, aux])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'main_output': dice_loss, 'aux_output': 'binary_crossentropy'},\n",
    "                  metrics={'main_output': dice, 'aux_output': 'acc'},\n",
    "                  loss_weights={'main_output': 1, 'aux_output': 0.5})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CustomDataGenerator(X_train, y_train, transform, BATCH_SIZE)\n",
    "\n",
    "# Use fixed samples instead to visualize histograms. There is currently a bug that prevents it\n",
    "# when a val generator is used.\n",
    "# Not aug val samples to keep the eval consistent.\n",
    "val_generator = CustomDataGenerator(X_val, y_val, lambda x, y: transform(x, y, augment=False), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on model\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 1, 224, 224) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 1, 224, 32)   351264      main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1, 224, 32)   128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_22 (ELU)                    (None, 1, 224, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 1, 224, 32)   9248        elu_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1, 224, 32)   128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_23 (ELU)                    (None, 1, 224, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 1, 112, 32)   4128        elu_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1, 112, 32)   128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_24 (ELU)                    (None, 1, 112, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1, 112, 32)   0           elu_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 1, 112, 64)   18496       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1, 112, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_25 (ELU)                    (None, 1, 112, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 1, 112, 64)   36928       elu_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1, 112, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_26 (ELU)                    (None, 1, 112, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 1, 56, 64)    16448       elu_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1, 56, 64)    256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_27 (ELU)                    (None, 1, 56, 64)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1, 56, 64)    0           elu_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 1, 56, 128)   73856       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1, 56, 128)   512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_28 (ELU)                    (None, 1, 56, 128)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 1, 56, 128)   147584      elu_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1, 56, 128)   512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_29 (ELU)                    (None, 1, 56, 128)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 1, 28, 128)   65664       elu_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1, 28, 128)   512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_30 (ELU)                    (None, 1, 28, 128)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 28, 128)   0           elu_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1, 28, 256)   295168      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1, 28, 256)   1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_31 (ELU)                    (None, 1, 28, 256)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 1, 28, 256)   590080      elu_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1, 28, 256)   1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_32 (ELU)                    (None, 1, 28, 256)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 1, 14, 256)   262400      elu_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1, 14, 256)   1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_33 (ELU)                    (None, 1, 14, 256)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 14, 256)   0           elu_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 1, 14, 512)   1180160     dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 1, 14, 512)   2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_34 (ELU)                    (None, 1, 14, 512)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 14, 512)   2359808     elu_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 1, 14, 512)   2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_35 (ELU)                    (None, 1, 14, 512)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1, 14, 512)   0           elu_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 1, 28, 512)   0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 28, 768)   0           up_sampling2d_4[0][0]            \n",
      "                                                                 elu_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 1, 28, 256)   1769728     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 28, 256)   1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_36 (ELU)                    (None, 1, 28, 256)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 1, 28, 256)   590080      elu_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1, 28, 256)   1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_37 (ELU)                    (None, 1, 28, 256)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1, 28, 256)   0           elu_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 1, 56, 256)   0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 56, 384)   0           up_sampling2d_5[0][0]            \n",
      "                                                                 elu_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 1, 56, 128)   442496      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1, 56, 128)   512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_38 (ELU)                    (None, 1, 56, 128)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 1, 56, 128)   147584      elu_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1, 56, 128)   512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_39 (ELU)                    (None, 1, 56, 128)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1, 56, 128)   0           elu_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 1, 112, 128)  0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1, 112, 192)  0           up_sampling2d_6[0][0]            \n",
      "                                                                 elu_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 1, 112, 64)   110656      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1, 112, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_40 (ELU)                    (None, 1, 112, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 1, 112, 64)   36928       elu_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1, 112, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_41 (ELU)                    (None, 1, 112, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1, 112, 64)   0           elu_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 1, 224, 64)   0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 224, 96)   0           up_sampling2d_7[0][0]            \n",
      "                                                                 elu_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 1, 224, 32)   27680       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1, 224, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_42 (ELU)                    (None, 1, 224, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 1, 224, 32)   9248        elu_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1, 224, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_43 (ELU)                    (None, 1, 224, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1, 224, 32)   0           elu_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 14, 512)   262656      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Conv2D)            (None, 1, 224, 1)    33          dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Flatten)            (None, 7168)         0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,822,017\n",
      "Trainable params: 8,815,169\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "run_id = str(datetime.now())\n",
    "model_checkpoint = ModelCheckpoint('./results/net.hdf5', monitor='val_loss', save_best_only=True)\n",
    "tb = TensorBoard(log_dir='./logs/{}'.format(run_id), histogram_freq=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=4, min_lr=1e-6)\n",
    "print('Training on model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import transform as tf\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# augmenter = ImageAugmenter(DataManager.EX_IMG_TARGET_COLS, DataManager.EX_IMG_TARGET_ROWS,\n",
    "#                            hflip=False, vflip=False,\n",
    "#                            rotation_deg=5,\n",
    "#                            translation_x_px=10,\n",
    "#                            translation_y_px=10)\n",
    "# new_x, new_y = transform(X_train[100], y_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " No algorithm worked!\n\t [[node model_1/conv2d_22/Conv2D (defined at <ipython-input-61-4c043c714309>:3) ]] [Op:__inference_train_function_8244]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-4c043c714309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(train_generator, validation_data=val_generator, validation_steps=X_val.shape[0],\n\u001b[1;32m      2\u001b[0m                      \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      callbacks=[model_checkpoint, reduce_lr, tb], max_queue_size=1000)\n\u001b[0m",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/mnt/storage/asopio/conda/envs/gpu02_conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m:  No algorithm worked!\n\t [[node model_1/conv2d_22/Conv2D (defined at <ipython-input-61-4c043c714309>:3) ]] [Op:__inference_train_function_8244]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator, validation_data=val_generator, validation_steps=X_val.shape[0],\n",
    "                     steps_per_epoch=X_train.shape[0], epochs=EPOCHS, verbose=2,\n",
    "                     callbacks=[model_checkpoint, reduce_lr, tb], max_queue_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
