{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/freshpate/miniconda3/envs/cern/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:37: UserWarning: You are currently using a nightly version of TensorFlow (2.9.0-dev20211227). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from data_manager import DataManager, load_img, list_images\n",
    "from data_generator import CustomDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from datetime import datetime\n",
    "import tensorflow\n",
    "from model import UNet\n",
    "import tensorflow.keras.activations as activations\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  ['/physical_device:GPU:0']\n",
      "Running on GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "print(\"Available GPUs: \", [gpu.name for gpu in gpus])\n",
    "gpu_index = 0\n",
    "print(f\"Running on GPU {gpu_index}\")\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[gpu_index], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[gpu_index], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.getcwd()\n",
    "manager = DataManager()\n",
    "BATCH_SIZE = 6\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "\n",
    "def resize2SquareKeepingAspectRation(img, size, interpolation):\n",
    "    h, w = img.shape[:2]\n",
    "    c = None if len(img.shape) < 3 else img.shape[2]\n",
    "    if h == w: \n",
    "        return cv2.resize(img, (size, size), interpolation)\n",
    "    if h > w: \n",
    "        dif = h\n",
    "    else:     \n",
    "        dif = w\n",
    "    x_pos = int((dif - w)/2.)\n",
    "    y_pos = int((dif - h)/2.)\n",
    "    if c is None:\n",
    "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "    return cv2.resize(mask, (size, size), interpolation)\n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn image into grayscale RGB\n",
    "    return np.array(Image.fromarray(img).convert(\"RGB\"))\n",
    "\n",
    "def save_img(img, img_idx, path, pid, is_mask=False):\n",
    "    filename = path + '/' + str(pid) + '_' + str(img_idx) \n",
    "    if is_mask: \n",
    "        filename += '_mask.png' \n",
    "        img = np.asarray(img, dtype=\"uint8\") # convert bool mask into uint8 so cv2 doesn't scream\n",
    "    else:\n",
    "        filename += '.png'\n",
    "        img = grays_to_RGB(img)\n",
    "    \n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (f\"Creation of the directory {path} failed\", end='\\r')\n",
    "\n",
    "def gen_dataset(imgs, dataset, pid, labels=None, typeof_dataset=None):\n",
    "    output_dir = BASE + '/data/'+dataset+'/'\n",
    "    if os.path.isdir(output_dir) is False:\n",
    "        make_dir(output_dir)\n",
    "    if typeof_dataset is not None: # this is only for train\n",
    "        output_dir+=typeof_dataset #+ '/'\n",
    "        if os.path.isdir(output_dir) is False:\n",
    "            make_dir(output_dir)\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        save_img(img, i, output_dir, pid)\n",
    "        if labels is not None: # this is only for train\n",
    "            save_img(labels[i], i, output_dir, pid, is_mask=True)\n",
    "    \n",
    "def list_images(directory, ext='jpg|jpeg|bmp|png|tif'):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if os.path.isfile(os.path.join(directory, f)) and re.match('([\\w]+\\.(?:' + ext + '))', f)]\n",
    "\n",
    "def preprocess(img, denoise=False):\n",
    "    \"\"\"\n",
    "    Preprocess step after image augmentation, and before feeding into conv net.\n",
    "    \"\"\"\n",
    "    if denoise:\n",
    "        img = cv2.fastNlMeansDenoising(img, h=7)\n",
    "    \n",
    "    img = resize2SquareKeepingAspectRation(img, DataManager.EX_IMG_TARGET_COLS, cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform(img, mask, augment=True):\n",
    "    \"\"\"\n",
    "    Transforms an (img, mask) pair with same augmentation params\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        pass\n",
    "        #img, mask = augmenter.augment_batch(np.array([img, mask]), same_transform=True)\n",
    "    img = preprocess(img)\n",
    "    mask = preprocess(mask).astype('float32')\n",
    "    return np.array([img]), np.array([mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = load_zipped_pickle(\"data/train.pkl\")\n",
    "# test_data = load_zipped_pickle(\"data/test.pkl\")\n",
    "# for data in tqdm(train_data, total=len(train_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     typeof_ds = data['dataset']\n",
    "#     labels = data['label'].T\n",
    "#     pacient = data['name']\n",
    "#     gen_dataset(imgs, \"train\", pacient, labels, typeof_ds)\n",
    "\n",
    "# for data in tqdm(test_data, total=len(test_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     pacient = data['name']\n",
    "#     gen_dataset(imgs, \"test\", pacient)\n",
    "# min_w = 1000\n",
    "# max_w = 0\n",
    "# min_h = 1000\n",
    "# max_h = 0\n",
    "# for data in tqdm(test_data, total=len(test_data)):\n",
    "#     imgs = data['video'].T\n",
    "#     pacient = data['name']\n",
    "#     if min_w > imgs.shape[1]:\n",
    "#         min_w = imgs.shape[1]\n",
    "#     if max_w < imgs.shape[1]:\n",
    "#         max_w = imgs.shape[1]\n",
    "#     if min_h > imgs.shape[2]:\n",
    "#         min_h = imgs.shape[2]\n",
    "#     if max_h < imgs.shape[2]:\n",
    "#         max_h = imgs.shape[2]\n",
    "\n",
    "# print(\"Min width: {} Max width: {}\".format(min_w, max_w))\n",
    "# print(\"Min height: {} Max height: {}\".format(min_h, max_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = manager.load_train_val_data(\"expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = CustomDataGenerator(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    (224, 224),\n",
    "    preprocess,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=5, #degrees\n",
    "    width_shift_range=10, #pixels, if <1 fraction\n",
    "    height_shift_range=10,\n",
    "    horizontal_flip=False,\n",
    "    shear_range=5,\n",
    "    rescale=1./255)\n",
    "    #preprocessing_function=preprocess)\n",
    "datagen.generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40909/2667375288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     rescale=1./255)\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#preprocessing_function=preprocess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdata_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_val' is not defined"
     ]
    }
   ],
   "source": [
    "datagen_val = CustomDataGenerator(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    (224, 224),\n",
    "    preprocess,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=5, #degrees\n",
    "    width_shift_range=10, #pixels, if <1 fraction\n",
    "    height_shift_range=10,\n",
    "    horizontal_flip=False,\n",
    "    shear_range=5,\n",
    "    rescale=1./255)\n",
    "    #preprocessing_function=preprocess)\n",
    "data_val.generator.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datagen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u_net_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_52 (Sequential)  (None, 224, 224, 32)      9760      \n",
      "                                                                 \n",
      " sequential_53 (Sequential)  (None, 112, 112, 64)      55808     \n",
      "                                                                 \n",
      " sequential_54 (Sequential)  (None, 56, 56, 128)       222208    \n",
      "                                                                 \n",
      " sequential_55 (Sequential)  (None, 28, 28, 256)       886784    \n",
      "                                                                 \n",
      " sequential_56 (Sequential)  (None, 14, 14, 512)       3543040   \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          multiple                  100353    \n",
      "                                                                 \n",
      " aux_output (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " sequential_57 (Sequential)  (None, 28, 28, 256)       1771520   \n",
      "                                                                 \n",
      " sequential_58 (Sequential)  (None, 56, 56, 128)       443392    \n",
      "                                                                 \n",
      " sequential_59 (Sequential)  (None, 112, 112, 64)      111104    \n",
      "                                                                 \n",
      " sequential_60 (Sequential)  (None, 224, 224, 32)      27904     \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          multiple                  289       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_61 (Sequential)  (None, 28, 28, 256)       2097152   \n",
      "                                                                 \n",
      " sequential_62 (Sequential)  (None, 56, 56, 128)       524288    \n",
      "                                                                 \n",
      " sequential_63 (Sequential)  (None, 112, 112, 64)      131072    \n",
      "                                                                 \n",
      " sequential_64 (Sequential)  (None, 224, 224, 32)      32768     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,957,442\n",
      "Trainable params: 9,951,554\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n",
      "Training on model\n"
     ]
    }
   ],
   "source": [
    "net = UNet(True)\n",
    "net.build((None, 224, 224, 1))\n",
    "net.summary()\n",
    "run_id = str(datetime.now())\n",
    "model_checkpoint = ModelCheckpoint('./results/net', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "tb = TensorBoard(log_dir='./logs/{}'.format(run_id), histogram_freq=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=4, min_lr=1e-6)\n",
    "print('Training on model')\n",
    "net.compile(optimizer='adam',\n",
    "                  loss={'output_1': 'binary_crossentropy', 'output_2': 'binary_crossentropy'},\n",
    "                  metrics={'output_1': tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), 'output_2': 'acc'},\n",
    "                  loss_weights={'output_1': 1, 'output_2': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(x, [y['main_output'], y['aux_output']], batch_size=2, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "735/735 [==============================] - 383s 516ms/step - loss: 0.2781 - output_1_loss: 0.0104 - output_2_loss: 0.5356 - output_1_io_u_3: 0.9999 - output_2_acc: 0.9653 - val_loss: 0.2834 - val_output_1_loss: 0.0013 - val_output_2_loss: 0.5643 - val_output_1_io_u_3: 0.9999 - val_output_2_acc: 0.9634 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "735/735 [==============================] - 369s 502ms/step - loss: 0.2688 - output_1_loss: 0.0012 - output_2_loss: 0.5352 - output_1_io_u_3: 0.9999 - output_2_acc: 0.9653 - val_loss: 0.2832 - val_output_1_loss: 0.0011 - val_output_2_loss: 0.5643 - val_output_1_io_u_3: 0.9999 - val_output_2_acc: 0.9634 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8f45eb340>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(datagen, validation_data=datagen_val, epochs=2, steps_per_epoch=len(X_train)//2, validation_steps=X_val.shape[0]//2, callbacks=[model_checkpoint, reduce_lr, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, validation_data=val_generator, validation_steps=X_val.shape[0],\n",
    "                     steps_per_epoch=X_train.shape[0], epochs=EPOCHS, verbose=2,\n",
    "                     callbacks=[model_checkpoint, reduce_lr, tb], max_queue_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
